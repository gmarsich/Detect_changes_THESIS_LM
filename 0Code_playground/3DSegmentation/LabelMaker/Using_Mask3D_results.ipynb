{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: labelmaker\n",
    "\n",
    "# With the following modifications:\n",
    "\n",
    "# (1) 5. Mask3D: environment as provided by the LabelMaker GitHub page (installation done a bit differently, however. See the txt file I created)\n",
    "\n",
    "# (2) 1. InternImage: I had to install:\n",
    "        # pip install -U openmim\n",
    "        # mim install mmsegmentation==0.27.0\n",
    "    # because I got an error, and followed the suggestions here: https://github.com/OpenGVLab/InternImage/issues/208\n",
    "\n",
    "# (3) 2. OVSeg: I had to do:\n",
    "        # export PYTHONPATH=$PYTHONPATH:~/Desktop/LabelMaker # because some code used as \"package\" (from labelmaker.label_data import get_ade150, get_replica, get_wordnet) was in the GitHub repository of LabelMaker\n",
    "    # I also had to install CLIP following these instructions, with some modifications: https://github.com/facebookresearch/ov-seg/blob/2a3a047973f9db3d3695d01098351f251ffc362e/INSTALL.md :\n",
    "        # python -m pip install -U setuptools # got setuptools-70.0.0\n",
    "        # cd third_party/CLIP # of the ov-seg GitHub repository\n",
    "        # python -m pip install -Ue . # to install CLIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "import numpy as np\n",
    "import scannet200_constants\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the results of Mask3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Hypersim scenes - Reduce occupied space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hypersim pointclous are too big to be processed, and it does not make sense to insist with having super detailed point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_pointclouds = '/local/home/gmarsich/data2TB/Hypersim/POINTCLOUDS' #TODO TOSET\n",
    "name_pointcloud = 'point_cloud_DEPTHS_TONEMAP_ai_007_008_cam_00_METERS.ply' #TODO TOSET\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(os.path.join(path_dir_pointclouds, name_pointcloud))\n",
    "\n",
    "# # Remove duplicates of points and save a new pointcloud: seems that the occupied memory is always the same\n",
    "# pcd = pcd.remove_duplicated_points()\n",
    "# name_pointcloud_noduplicates = os.path.splitext(name_pointcloud)[0] + '_NODUPLICATES.ply'\n",
    "# new_path_pointcloud = os.path.join(path_dir_pointclouds, name_pointcloud_noduplicates)\n",
    "# o3d.io.write_point_cloud(new_path_pointcloud, pcd)\n",
    "\n",
    "# Undersample the point cloud\n",
    "voxel_size = 0.03  # TODO TOSET: for point_cloud_DEPTHS_TONEMAP_ai_007_008_cam_00_METERS.ply voxel_size = 0.015 gives a point cloud of more or less 98 MB\n",
    "downsampled_pcd = pcd.voxel_down_sample(voxel_size)\n",
    "name_pointcloud_downsampled = os.path.splitext(name_pointcloud)[0] + '_DOWNSAMPLED.ply'\n",
    "new_path_pointcloud = os.path.join(path_dir_pointclouds, name_pointcloud_downsampled)\n",
    "o3d.io.write_point_cloud(new_path_pointcloud, downsampled_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the downsampled point cloud\n",
    "pcd_downsampled = o3d.io.read_point_cloud(os.path.join(path_dir_pointclouds, name_pointcloud_downsampled))\n",
    "o3d.visualization.draw_geometries([pcd_downsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preprocessing to get the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's build a legend showing what was found in the scene (that was represented with a point cloud):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get the list of objects that appear in the segmentation (use the files provided from the work of Mask3D)\n",
    "#\n",
    "\n",
    "dataset = 'hypersim' # possibilities: 'hypersim', 'arkitscenes' #TODO TOSET\n",
    "\n",
    "# For ARKitScenes\n",
    "scene_id_num = 42898070 # TODO TOSET: change if needed\n",
    "scene_id = str(scene_id_num)\n",
    "\n",
    "# For Hypersim\n",
    "\n",
    "\n",
    "path_predictions = os.path.join(\"/local/home/gmarsich/data2TB/Hypersim/POINTCLOUDS/TODO/intermediate/scannet200_mask3d_1/predictions.txt\") # TODO TOSET: change if necessary\n",
    "\n",
    "\n",
    "def build_legend(path_predictions):\n",
    "    with open(path_predictions, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        filename = parts[0]\n",
    "        file_number = filename.split('/')[1].split('.')[0]\n",
    "        object_ID = int(parts[1])\n",
    "        confidence = float(parts[2])\n",
    "\n",
    "        predictions.append([file_number, object_ID, confidence])\n",
    "\n",
    "    # Build a list with the info that I need\n",
    "    objects = []\n",
    "\n",
    "    for prediction in predictions:\n",
    "        object_ID = prediction[1]\n",
    "        \n",
    "        # Find the object_ID in the objects list\n",
    "        found = False\n",
    "        for obj in objects:\n",
    "            if obj[0] == object_ID:\n",
    "                obj[1] += 1\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        # If the object_ID was not found, add it to the list with a count of 1\n",
    "        if not found:\n",
    "            objects.append([object_ID, 1])\n",
    "\n",
    "\n",
    "    #\n",
    "    # Build a big table with the correspondences between VALID_CLASS_IDS_200, CLASS_LABELS_200 and SCANNET_COLOR_MAP_200 from scannet200_constants\n",
    "    #\n",
    "\n",
    "    table_scannet200 = []\n",
    "\n",
    "    for class_id, label in zip(scannet200_constants.VALID_CLASS_IDS_200, scannet200_constants.CLASS_LABELS_200):\n",
    "        color = scannet200_constants.SCANNET_COLOR_MAP_200[class_id]\n",
    "        table_scannet200.append((class_id, label, color))\n",
    "\n",
    "    # An alternative could be to get the colours from the point cloud and search for their assciated IDs (and name of the object) on\n",
    "        # https://github.com/ScanNet/ScanNet/blob/master/BenchmarkScripts/ScanNet200/scannet200_constants.py\n",
    "\n",
    "\n",
    "    #\n",
    "    # Use the big table to add information to the list objects\n",
    "    #\n",
    "\n",
    "    # Add label and colour\n",
    "    for obj in objects:\n",
    "        object_ID = obj[0]\n",
    "        \n",
    "        for entry in table_scannet200:\n",
    "            class_id, label, color = entry\n",
    "            if object_ID == class_id:\n",
    "                obj.append(label)\n",
    "                obj.append(color)\n",
    "                break\n",
    "\n",
    "    # Sort the objects list by the ID (first element of each sublist)\n",
    "    objects.sort(key=lambda x: x[0])\n",
    "    return objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = build_legend(path_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each element of the list `objects` has $4$ elements:\n",
    "\n",
    "- `objects[i][0]`: ID of the class\n",
    "\n",
    "- `objects[i][1]`: number of instances of the class\n",
    "\n",
    "- `objects[i][2]`: name of the class in English\n",
    "\n",
    "- `objects[i][3]`: colour of the instances of the class in RGB (max values: $(255, 255, 255)$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the legend and the point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the image with the legend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get the legend for objects in the scene\n",
    "#\n",
    "\n",
    "plt.figure(figsize=(0.001, len(objects) * 0.2))\n",
    "\n",
    "# Loop over the objects and add them to the plot\n",
    "for i, obj in enumerate(objects):\n",
    "    object_ID = obj[0]\n",
    "    count = obj[1]\n",
    "    label = obj[2]\n",
    "    color = [c/255 for c in obj[3]]  # normalize the color values\n",
    "\n",
    "    plt.scatter([], [], c=[color], label=f'ID: {object_ID}, Name: {label}, Count: {count}', s=100)\n",
    "    \n",
    "# Create a legend\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='large')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the segmentation with Mask3D (computed by LabelMaker)\n",
    "pcd_mask3D = o3d.io.read_point_cloud(os.path.join(\"/local/home/gmarsich/data2TB/LabelMaker/processed_ARKitScenes\", str(scene_id), \"intermediate/scannet200_mask3d_1/mesh_labelled.ply\")) # TODO TOSET: change the name of the point cloud to open\n",
    "o3d.visualization.draw_geometries([pcd_mask3D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the point cloud with the labels of the classes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
