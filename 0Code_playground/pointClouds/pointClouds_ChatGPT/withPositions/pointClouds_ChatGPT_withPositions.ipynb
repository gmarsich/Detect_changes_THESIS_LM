{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: thesisPlayground_pointClouds_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was helped by these discussions / resources:\n",
    "- https://github.com/apple/ml-hypersim/blob/main/contrib/mikeroberts3000/jupyter/00_projecting_points_into_hypersim_images.ipynb\n",
    "- https://github.com/apple/ml-hypersim/issues/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using positions - Point cloud from one image using the camera-space (use M_cam_from_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark that everything was prepared as if the code had to handle more than one image. However, working in the camera-space would require some modifications in the code, so at the end this section just works to render an image, I guess. A revision is needed in any case; I kept the code because maybe it will turn out useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_file(file_paths, dataset_key):\n",
    "    data = []\n",
    "    for file in file_paths:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(np.array(f[dataset_key]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_M_cam_from_world(frame_id, camera_dir):\n",
    "\n",
    "    camera_positions_hdf5_file    = os.path.join(camera_dir, \"camera_keyframe_positions.hdf5\")\n",
    "    camera_orientations_hdf5_file = os.path.join(camera_dir, \"camera_keyframe_orientations.hdf5\")\n",
    "\n",
    "    with h5py.File(camera_positions_hdf5_file,    \"r\") as f: camera_positions    = f[\"dataset\"][:]\n",
    "    with h5py.File(camera_orientations_hdf5_file, \"r\") as f: camera_orientations = f[\"dataset\"][:]\n",
    "\n",
    "    # get position and rotation matrix for Hypersim image\n",
    "    camera_position_world = camera_positions[frame_id]\n",
    "    R_world_from_cam      = camera_orientations[frame_id]\n",
    "\n",
    "    t_world_from_cam = np.array(camera_position_world).reshape((3, 1))\n",
    "    R_cam_from_world = np.array(R_world_from_cam).T\n",
    "    t_cam_from_world = -R_cam_from_world @ t_world_from_cam\n",
    "\n",
    "    M_cam_from_world = np.block([[R_cam_from_world, t_cam_from_world],\n",
    "                                 [np.zeros((1, 3)), np.array([[1.0]])]])\n",
    "    \n",
    "    return M_cam_from_world\n",
    "    \n",
    "\n",
    "def extract_frame_id(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    frame_id = int(base.split('.')[1])\n",
    "    return frame_id\n",
    "\n",
    "\n",
    "def generate_point_cloud(image_files, positions, camera_dir):\n",
    "    point_clouds = []\n",
    "\n",
    "    for img_file, position in zip(image_files, positions):\n",
    "        # Extract frame ID from the image filename\n",
    "        frame_id = extract_frame_id(img_file)\n",
    "\n",
    "        # Build the M_cam_from_world matrix for the current frame\n",
    "        M_cam_from_world = build_M_cam_from_world(frame_id, camera_dir)\n",
    "\n",
    "        # Extracting 3D coordinates of each pixel from positions\n",
    "        X = position[:, :, 0]\n",
    "        Y = position[:, :, 1]\n",
    "        Z = position[:, :, 2]\n",
    "\n",
    "        # Stack X, Y, Z to get point cloud\n",
    "        point_cloud = np.stack((X, Y, Z), axis=-1)\n",
    "\n",
    "        # Reshape point cloud to flatten the array\n",
    "        point_cloud_flat = point_cloud.reshape(-1, 3)\n",
    "\n",
    "        # Convert world-space points to camera-space points\n",
    "        homogeneous_points = np.hstack((point_cloud_flat, np.ones((point_cloud_flat.shape[0], 1))))\n",
    "        camera_space_points = np.dot(M_cam_from_world, homogeneous_points.T).T[:, :3]\n",
    "\n",
    "        # Convert camera-space points to Open3D point cloud format\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(camera_space_points)\n",
    "\n",
    "        # Append point cloud to list\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "def render_point_cloud(point_cloud):\n",
    "\n",
    "    pcd = point_cloud\n",
    "\n",
    "    # Create a visualization window\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "\n",
    "    # Add the point cloud to the visualization window\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set the render options (optional)\n",
    "    render_options = vis.get_render_option()\n",
    "    render_options.point_size = 2  # Adjust the size of the points\n",
    "\n",
    "    # Render the visualization\n",
    "    vis.run()\n",
    "\n",
    "    # Close the visualization window\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_007_008'  # name of the scene, with format ai_VVV_NNN\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "# Get directory for info\n",
    "camera_dir = os.path.join(base_path, scene, \"_detail\", cam_xx)\n",
    "\n",
    "# Get list of image and position HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "position_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.position.hdf5')))\n",
    "\n",
    "# HERE WE SELECT JUST ONE IMAGE\n",
    "frame = 0\n",
    "image_files = [image_files[frame]]\n",
    "position_files = [position_files[frame]]\n",
    "\n",
    "\n",
    "# Ensure the number of image and position files match\n",
    "if len(image_files) != len(position_files):\n",
    "    raise ValueError(\"The number of image files and position files do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and position data\n",
    "images = load_hdf5_file(image_files, 'dataset')\n",
    "positions = load_hdf5_file(position_files, 'dataset')\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(image_files, positions, camera_dir)\n",
    "\n",
    "cloud = point_clouds[0]\n",
    "print(cloud)\n",
    "\n",
    "render_point_cloud(point_clouds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using positions - Point cloud from more images using the world-space\n",
    "### Colour given by the height from the floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_file(file_paths, dataset_key):\n",
    "    data = []\n",
    "    for file in file_paths:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(np.array(f[dataset_key]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_point_cloud(images, positions):\n",
    "    point_clouds = []\n",
    "\n",
    "    for position in positions:\n",
    "        # Extracting 3D coordinates of each pixel from positions\n",
    "        X = position[:, :, 0]\n",
    "        Y = position[:, :, 1]\n",
    "        Z = position[:, :, 2]\n",
    "\n",
    "        # Stack X, Y, Z to get point cloud\n",
    "        point_cloud = np.stack((X, Y, Z), axis=-1)\n",
    "\n",
    "        # Convert numpy array to Open3D point cloud format\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud.reshape(-1, 3))\n",
    "\n",
    "        # Append point cloud to list\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "def combine_point_clouds(point_clouds):\n",
    "    # Combine all point clouds into a single point cloud\n",
    "    combined_cloud = o3d.geometry.PointCloud()\n",
    "    for pcd in point_clouds:\n",
    "        combined_cloud += pcd\n",
    "\n",
    "    return combined_cloud\n",
    "\n",
    "\n",
    "def render_point_cloud(point_cloud):\n",
    "\n",
    "    pcd = point_cloud\n",
    "\n",
    "    # Create a visualization window\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "\n",
    "    # Add the point cloud to the visualization window\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set the render options (optional)\n",
    "    render_options = vis.get_render_option()\n",
    "    render_options.point_size = 2  # Adjust the size of the points\n",
    "\n",
    "    # Render the visualization\n",
    "    vis.run()\n",
    "\n",
    "    # Close the visualization window\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_007_008'  # name of the scene, with format ai_VVV_NNN\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "# Get list of image and position HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "position_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.position.hdf5')))\n",
    "\n",
    "# Ensure the number of image and position files match\n",
    "if len(image_files) != len(position_files):\n",
    "    raise ValueError(\"The number of image files and position files do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and position data\n",
    "images = load_hdf5_file(image_files, 'dataset')\n",
    "positions = load_hdf5_file(position_files, 'dataset')\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(images, positions)\n",
    "\n",
    "# Combine all individual point clouds into a single point cloud\n",
    "combined_point_cloud = combine_point_clouds(point_clouds)\n",
    "\n",
    "o3d.io.write_point_cloud(\"point_cloud.ply\", combined_point_cloud) # to save the point cloud as .ply file\n",
    "\n",
    "# Render the visualization of the combined point cloud\n",
    "render_point_cloud(combined_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to open a point cloud\n",
    "\n",
    "# pcd = o3d.io.read_point_cloud(\"/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds/pointClouds_ChatGPT/point_cloud.ply\")\n",
    "# render_point_cloud(pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using positions - Point cloud from more images using the world-space\n",
    "### Colour given by the objects (i.e., by the *color.hdf5 files)\n",
    "Remark that no tonemapping has been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_hdf5_file(file_paths, dataset_key):\n",
    "    data = []\n",
    "    for file in file_paths:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(np.array(f[dataset_key]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_point_cloud(images, positions):\n",
    "    point_clouds = []\n",
    "\n",
    "    for i, (image, position) in enumerate(zip(images, positions)):\n",
    "        # Extracting 3D coordinates of each pixel from positions\n",
    "        X = position[:, :, 0]\n",
    "        Y = position[:, :, 1]\n",
    "        Z = position[:, :, 2]\n",
    "\n",
    "        # Extracting color information from images\n",
    "        R = image[:, :, 0]\n",
    "        G = image[:, :, 1]\n",
    "        B = image[:, :, 2]\n",
    "\n",
    "\n",
    "        # # Uncomment the following to have different colors\n",
    "        \n",
    "        # # Debug statements to check the range of the raw image data\n",
    "        # print(f\"Raw image {i} ranges: R min {R.min()}, max {R.max()}, G min {G.min()}, max {G.max()}, B min {B.min()}, max {B.max()}\")\n",
    "\n",
    "        # # Find the maximum value across all color channels to normalize the colors\n",
    "        # max_value = max(R.max(), G.max(), B.max())\n",
    "        # if max_value > 0:\n",
    "        #     R = R / max_value\n",
    "        #     G = G / max_value\n",
    "        #     B = B / max_value\n",
    "\n",
    "        # Stack X, Y, Z to get point cloud coordinates\n",
    "        point_cloud = np.stack((X, Y, Z), axis=-1)\n",
    "        # Stack R, G, B to get point cloud colors\n",
    "        colors = np.stack((R, G, B), axis=-1)\n",
    "\n",
    "        # Convert numpy array to Open3D point cloud format\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud.reshape(-1, 3))\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors.reshape(-1, 3))\n",
    "\n",
    "        # Append point cloud to list\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "def combine_point_clouds(point_clouds):\n",
    "    # Combine all point clouds into a single point cloud\n",
    "    combined_cloud = o3d.geometry.PointCloud()\n",
    "    for pcd in point_clouds:\n",
    "        combined_cloud += pcd\n",
    "\n",
    "    return combined_cloud\n",
    "\n",
    "\n",
    "def render_point_cloud(point_cloud):\n",
    "    pcd = point_cloud\n",
    "\n",
    "    # Create a visualization window\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set the render options (optional)\n",
    "    render_options = vis.get_render_option()\n",
    "    render_options.point_size = 2  # Adjust the size of the points\n",
    "\n",
    "    # Render the visualization\n",
    "    vis.run()\n",
    "\n",
    "    # Close the visualization window\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_007_008'\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "# Get list of image and position HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "position_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.position.hdf5')))\n",
    "\n",
    "# Ensure the number of image and position files match\n",
    "if len(image_files) != len(position_files):\n",
    "    raise ValueError(\"The number of image files and position files do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and position data\n",
    "images = load_hdf5_file(image_files, 'dataset')\n",
    "positions = load_hdf5_file(position_files, 'dataset')\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(images, positions)\n",
    "\n",
    "# Combine all individual point clouds into a single point cloud\n",
    "combined_point_cloud = combine_point_clouds(point_clouds)\n",
    "\n",
    "# Render the visualization of the combined point cloud\n",
    "render_point_cloud(combined_point_cloud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using positions - Point cloud from more images using the world-space\n",
    "### Colour given by a tonemapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one first needs to preprocess the `*color.hdf5 files`, applying a tonemap. I considered the same tonemap as the one used by Hypersim (and described in this code: https://github.com/apple/ml-hypersim/blob/main/code/python/tools/scene_generate_images_tonemap.py). I created a file `apply_tonemap.py` that converts `.color.hdf5` files into hdf5 files with the tonemap, and saves them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import apply_tonemap # uncomment if you need to get the hdf5 files with tonemap\n",
    "\n",
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_007_008'\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "in_dir = os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5')\n",
    "out_dir = os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', 'scene_' + cam_xx + '_final_hdf5_TONEMAP')\n",
    "\n",
    "\n",
    "# apply_tonemap.apply_tonemapping_to_directory(in_dir, out_dir) # uncomment if you need to get the hdf5 files with tonemap\n",
    "\n",
    "# Get list of image and position HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(out_dir, '*.color.hdf5')))\n",
    "position_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.position.hdf5')))\n",
    "\n",
    "# Ensure the number of image and position files match\n",
    "if len(image_files) != len(position_files):\n",
    "    raise ValueError(\"The number of image files and position files do not match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_hdf5_file(file_paths, dataset_key):\n",
    "    data = []\n",
    "    for file in file_paths:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(np.array(f[dataset_key]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_point_cloud(images, positions):\n",
    "    point_clouds = []\n",
    "\n",
    "    for i, (image, position) in enumerate(zip(images, positions)):\n",
    "        # Extracting 3D coordinates of each pixel from positions\n",
    "        X = position[:, :, 0]\n",
    "        Y = position[:, :, 1]\n",
    "        Z = position[:, :, 2]\n",
    "\n",
    "        # Extracting color information from images\n",
    "        R = image[:, :, 0]\n",
    "        G = image[:, :, 1]\n",
    "        B = image[:, :, 2]\n",
    "\n",
    "        # Debug statements to check the range of the raw image data\n",
    "        print(f\"Raw image {i} ranges: R min {R.min()}, max {R.max()}, G min {G.min()}, max {G.max()}, B min {B.min()}, max {B.max()}\")\n",
    "\n",
    "        # Find the maximum value across all color channels to normalize the colors\n",
    "        max_value = max(R.max(), G.max(), B.max())\n",
    "        if max_value > 0:\n",
    "            R = R / max_value\n",
    "            G = G / max_value\n",
    "            B = B / max_value\n",
    "\n",
    "        # Stack X, Y, Z to get point cloud coordinates\n",
    "        point_cloud = np.stack((X, Y, Z), axis=-1)\n",
    "        # Stack R, G, B to get point cloud colors\n",
    "        colors = np.stack((R, G, B), axis=-1)\n",
    "\n",
    "        # Convert numpy array to Open3D point cloud format\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud.reshape(-1, 3))\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors.reshape(-1, 3))\n",
    "\n",
    "        # Append point cloud to list\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "def combine_point_clouds(point_clouds):\n",
    "    # Combine all point clouds into a single point cloud\n",
    "    combined_cloud = o3d.geometry.PointCloud()\n",
    "    for pcd in point_clouds:\n",
    "        combined_cloud += pcd\n",
    "\n",
    "    return combined_cloud\n",
    "\n",
    "\n",
    "def render_point_cloud(point_cloud):\n",
    "    pcd = point_cloud\n",
    "\n",
    "    # Create a visualization window\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set the render options (optional)\n",
    "    render_options = vis.get_render_option()\n",
    "    render_options.point_size = 2  # Adjust the size of the points\n",
    "\n",
    "    # Render the visualization\n",
    "    vis.run()\n",
    "\n",
    "    # Close the visualization window\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and position data\n",
    "images = load_hdf5_file(image_files, 'tonemapped_rgb')\n",
    "positions = load_hdf5_file(position_files, 'dataset')\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(images, positions)\n",
    "\n",
    "# Combine all individual point clouds into a single point cloud\n",
    "combined_point_cloud = combine_point_clouds(point_clouds)\n",
    "\n",
    "# Render the visualization of the combined point cloud\n",
    "render_point_cloud(combined_point_cloud)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisPlayground_pointClouds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
