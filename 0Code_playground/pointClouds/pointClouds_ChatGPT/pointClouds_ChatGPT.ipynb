{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: thesisPlayground_pointClouds_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should need:\n",
    "- image(s) (RGB, or the hdf5)\n",
    "- depths\n",
    "- intrinsics matrix\n",
    "- camera poses (when having multiple images to put together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Matrix for the scene:\n",
      "[[1.43810735e+03 0.00000000e+00 5.12000000e+02]\n",
      " [0.00000000e+00 1.43810735e+03 3.83920000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def get_intrinsics_from_metadata(scene_row):\n",
    "    \"\"\"\n",
    "    Derive the intrinsic matrix from metadata.\n",
    "\n",
    "    Parameters:\n",
    "        scene_row (pd.Series): Metadata row for the scene.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The intrinsic matrix K.\n",
    "    \"\"\"\n",
    "    # Extract the necessary parameters from the metadata\n",
    "    img_width = scene_row[\"settings_output_img_width\"]\n",
    "    img_height = scene_row[\"settings_output_img_height\"]\n",
    "    focal_length = scene_row[\"camera_physical_focal_length\"]\n",
    "    sensor_width = scene_row[\"camera_physical_film_width\"]\n",
    "\n",
    "    # Calculate fx and fy using the focal length and sensor width\n",
    "    fx = focal_length / sensor_width * img_width\n",
    "    fy = fx  # Assuming square pixels\n",
    "\n",
    "    # Calculate the principal point (cx, cy) considering horizontal and vertical shifts\n",
    "    cx = img_width / 2 + scene_row[\"camera_physical_horizontal_shift\"]\n",
    "    cy = img_height / 2 + scene_row[\"camera_physical_lens_shift\"]\n",
    "\n",
    "    # Construct the intrinsic matrix\n",
    "    intrinsic_matrix = np.array([\n",
    "        [fx, 0, cx],\n",
    "        [0, fy, cy],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    return intrinsic_matrix\n",
    "\n",
    "\n",
    "\n",
    "def get_intrinsics_with_tilt_shift(path_metadata, scene_name):\n",
    "    \"\"\"\n",
    "    Load camera metadata from a CSV file and compute the intrinsic matrix considering tilt-shift parameters.\n",
    "\n",
    "    Parameters:\n",
    "        path_metadata (str): Path to the metadata CSV file.\n",
    "        scene_name (str): Name of the scene to analyze.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The updated intrinsic matrix K.\n",
    "    \"\"\"\n",
    "    # Load the metadata CSV file\n",
    "    df = pd.read_csv(path_metadata)\n",
    "    \n",
    "    # Filter the DataFrame to get the row corresponding to the specified scene\n",
    "    scene_row = df[df['scene_name'] == scene_name]\n",
    "    \n",
    "    if scene_row.empty:\n",
    "        raise ValueError(f\"Scene '{scene_name}' not found in the metadata.\")\n",
    "    \n",
    "    # Use the first matching row\n",
    "    scene_row = scene_row.iloc[0]\n",
    "    \n",
    "    # Get the intrinsic matrix from metadata\n",
    "    intrinsic_matrix = get_intrinsics_from_metadata(scene_row)\n",
    "    \n",
    "    return intrinsic_matrix\n",
    "\n",
    "\n",
    "# TEST\n",
    "path_metadata = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds/pointClouds_ChatGPT/metadata_camera_parameters.csv'\n",
    "scene = 'ai_007_008'  # name of the scene, with format ai_VVV_NNN\n",
    "intrinsics = get_intrinsics_with_tilt_shift(path_metadata, scene)\n",
    "print(\"Intrinsic Matrix for the scene:\")\n",
    "print(intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for multimple images\n",
    "\n",
    "# def get_camera_pose(scene_row):\n",
    "#     \"\"\"\n",
    "#     Extract the camera pose from the metadata row.\n",
    "\n",
    "#     Parameters:\n",
    "#         scene_row (pd.Series): Metadata row for the scene.\n",
    "\n",
    "#     Returns:\n",
    "#         np.ndarray: The camera extrinsic matrix (4x4).\n",
    "#     \"\"\"\n",
    "#     # Extract rotation matrix\n",
    "#     R = np.array([\n",
    "#         [scene_row[\"M_cam_from_uv_00\"], scene_row[\"M_cam_from_uv_01\"], scene_row[\"M_cam_from_uv_02\"]],\n",
    "#         [scene_row[\"M_cam_from_uv_10\"], scene_row[\"M_cam_from_uv_11\"], scene_row[\"M_cam_from_uv_12\"]],\n",
    "#         [scene_row[\"M_cam_from_uv_20\"], scene_row[\"M_cam_from_uv_21\"], scene_row[\"M_cam_from_uv_22\"]],\n",
    "#     ])\n",
    "    \n",
    "#     # Extract translation vector\n",
    "#     t = np.array([scene_row[\"M_proj_03\"], scene_row[\"M_proj_13\"], scene_row[\"M_proj_23\"]])\n",
    "    \n",
    "#     # Construct the extrinsic matrix\n",
    "#     extrinsic_matrix = np.eye(4)\n",
    "#     extrinsic_matrix[:3, :3] = R\n",
    "#     extrinsic_matrix[:3, 3] = t\n",
    "    \n",
    "#     return extrinsic_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_data(image_files, depth_files):\n",
    "    \"\"\"\n",
    "    Load images and depth data from multiple HDF5 files.\n",
    "    \n",
    "    Parameters:\n",
    "        image_files (list): List of paths to the HDF5 files containing images.\n",
    "        depth_files (list): List of paths to the HDF5 files containing depth maps.\n",
    "    \n",
    "    Returns:\n",
    "        images (list): List of images.\n",
    "        depths (list): List of depth maps.\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    depths = []\n",
    "\n",
    "    for image_file, depth_file in zip(image_files, depth_files):\n",
    "        with h5py.File(image_file, 'r') as f:\n",
    "            images.append(np.array(f['dataset']))  # Adjust the key according to your HDF5 structure\n",
    "\n",
    "        with h5py.File(depth_file, 'r') as f:\n",
    "            depths.append(np.array(f['dataset']))  # Adjust the key according to your HDF5 structure\n",
    "\n",
    "    return images, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "# def generate_point_cloud(images, depths, intrinsic_matrix):\n",
    "#     \"\"\"\n",
    "#     Generate point clouds from images and depth maps.\n",
    "    \n",
    "#     Parameters:\n",
    "#         images (list): List of images.\n",
    "#         depths (list): List of depth maps.\n",
    "#         intrinsic_matrix (np.ndarray): Intrinsic matrix of the camera.\n",
    "    \n",
    "#     Returns:\n",
    "#         point_clouds (list): List of Open3D PointCloud objects.\n",
    "#     \"\"\"\n",
    "\n",
    "#     point_clouds = []\n",
    "\n",
    "#     for image, depth in zip(images, depths):\n",
    "#         # Create an empty point cloud\n",
    "#         points = []\n",
    "\n",
    "#         h, w = depth.shape\n",
    "\n",
    "#         u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "#         u = u.flatten()\n",
    "#         v = v.flatten()\n",
    "\n",
    "#         z = depth.flatten()\n",
    "\n",
    "        \n",
    "#         valid = z > 0\n",
    "#         u = u[valid]\n",
    "#         v = v[valid]\n",
    "#         z = z[valid]\n",
    "\n",
    "#         x = (u - intrinsic_matrix[0, 2]) / intrinsic_matrix[0, 0]\n",
    "#         y = (v - intrinsic_matrix[1, 2]) / intrinsic_matrix[1, 1]\n",
    "\n",
    "#         # C\n",
    "#         x = x * z\n",
    "#         y = y * z\n",
    "\n",
    "#         points = np.vstack((x, y, z)).T\n",
    "        \n",
    "#         pcd = o3d.geometry.PointCloud()\n",
    "#         pcd.points = o3d.utility.Vector3dVector(points)\n",
    "#         point_clouds.append(pcd)\n",
    "    \n",
    "#     return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "# ORIGINAL:\n",
    "\n",
    "# def generate_point_cloud(images, depths, intrinsic_matrix, extrinsic_matrices):\n",
    "#     \"\"\"\n",
    "#     Generate point clouds from images and depth maps and apply the camera extrinsic transformations.\n",
    "\n",
    "#     Parameters:\n",
    "#         images (list): List of images.\n",
    "#         depths (list): List of depth maps.\n",
    "#         intrinsic_matrix (np.ndarray): Intrinsic matrix of the camera.\n",
    "#         extrinsic_matrices (list): List of camera extrinsic matrices.\n",
    "\n",
    "#     Returns:\n",
    "#         point_clouds (list): List of Open3D PointCloud objects.\n",
    "#     \"\"\"\n",
    "#     point_clouds = []\n",
    "\n",
    "#     for image, depth, extrinsic_matrix in zip(images, depths, extrinsic_matrices):\n",
    "\n",
    "#         # Get the image dimensions\n",
    "#         h, w = depth.shape\n",
    "\n",
    "#         # Create a mesh grid of pixel coordinates\n",
    "#         u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "#         u = u.flatten()\n",
    "#         v = v.flatten()\n",
    "\n",
    "#         # Get the corresponding depth values\n",
    "#         z = depth.flatten()\n",
    "\n",
    "#         # Filter out points with zero depth\n",
    "#         valid = z > 0\n",
    "#         u = u[valid]\n",
    "#         v = v[valid]\n",
    "#         z = z[valid]\n",
    "\n",
    "#         # Convert pixel coordinates to normalized image coordinates; create 3D points in the camera coordinate system\n",
    "#         x = (u - intrinsic_matrix[0, 2]) / intrinsic_matrix[0, 0] * z\n",
    "#         y = (v - intrinsic_matrix[1, 2]) / intrinsic_matrix[1, 1] * z\n",
    "\n",
    "#         # Stack the coordinates into a single array\n",
    "#         points = np.vstack((x, y, z)).T\n",
    "\n",
    "#         # Apply extrinsic transformation\n",
    "#         ones = np.ones((points.shape[0], 1))\n",
    "#         points_homogeneous = np.hstack((points, ones))\n",
    "#         points_transformed = (extrinsic_matrix @ points_homogeneous.T).T[:, :3]\n",
    "\n",
    "#         # Create Open3D PointCloud object and add it to the list\n",
    "#         pcd = o3d.geometry.PointCloud()\n",
    "#         pcd.points = o3d.utility.Vector3dVector(points_transformed)\n",
    "#         point_clouds.append(pcd)\n",
    "\n",
    "#     return point_clouds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes/ai_007_008/images/scene_cam_00_final_hdf5/*.color.hdf5\n",
      "['/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes/ai_007_008/images/scene_cam_00_final_hdf5/frame.0000.color.hdf5']\n",
      "Intrinsic Matrix for the scene:\n",
      "[[1.43810735e+03 0.00000000e+00 5.12000000e+02]\n",
      " [0.00000000e+00 1.43810735e+03 3.83920000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def generate_point_cloud(images, depths, intrinsic_matrix, extrinsic_matrices):\n",
    "    \"\"\"\n",
    "    Generate point clouds from images and depth maps and apply the camera extrinsic transformations.\n",
    "\n",
    "    Parameters:\n",
    "        images (list): List of images.\n",
    "        depths (list): List of depth maps.\n",
    "        intrinsic_matrix (np.ndarray): Intrinsic matrix of the camera.\n",
    "        extrinsic_matrices (list): List of camera extrinsic matrices.\n",
    "\n",
    "    Returns:\n",
    "        point_clouds (list): List of Open3D PointCloud objects.\n",
    "    \"\"\"\n",
    "    point_clouds = []\n",
    "\n",
    "    for image, depth in zip(images, depths):\n",
    "\n",
    "        # Get the image dimensions\n",
    "        h, w = depth.shape\n",
    "\n",
    "        # Create a mesh grid of pixel coordinates\n",
    "        u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "        u = u.flatten()\n",
    "        v = v.flatten()\n",
    "\n",
    "        # Get the corresponding depth values\n",
    "        z = depth.flatten()\n",
    "\n",
    "        # Filter out points with zero depth\n",
    "        valid = z > 0\n",
    "        u = u[valid]\n",
    "        v = v[valid]\n",
    "        z = z[valid]\n",
    "\n",
    "        # Convert pixel coordinates to normalized image coordinates; create 3D points in the camera coordinate system\n",
    "        x = (u - intrinsic_matrix[0, 2]) / intrinsic_matrix[0, 0] * z\n",
    "        y = (v - intrinsic_matrix[1, 2]) / intrinsic_matrix[1, 1] * z\n",
    "\n",
    "        # Stack the coordinates into a single array\n",
    "        points = np.vstack((x, y, z)).T\n",
    "\n",
    "        # # Apply extrinsic transformation\n",
    "        # ones = np.ones((points.shape[0], 1))\n",
    "        # points_homogeneous = np.hstack((points, ones))\n",
    "        # points_transformed = (extrinsic_matrix @ points_homogeneous.T).T[:, :3]\n",
    "\n",
    "        # Create Open3D PointCloud object and add it to the list\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        #pcd.points = o3d.utility.Vector3dVector(points_transformed)\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST\n",
    "path_metadata = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds/pointClouds_ChatGPT/metadata_camera_parameters.csv'\n",
    "\n",
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_007_008'  # name of the scene, with format ai_VVV_NNN\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "# Get list of image and depth HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "depth_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.depth_meters.hdf5')))\n",
    "\n",
    "print(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5'))\n",
    "\n",
    "print(image_files)\n",
    "\n",
    "# Ensure the number of image and depth files match\n",
    "if len(image_files) != len(depth_files):\n",
    "    raise ValueError(\"The number of image files and depth files do not match.\")\n",
    "\n",
    "# Get the intrinsic matrix for the scene\n",
    "intrinsics = get_intrinsics_with_tilt_shift(path_metadata, scene)\n",
    "print(\"Intrinsic Matrix for the scene:\")\n",
    "print(intrinsics)\n",
    "\n",
    "# Load images and depth data\n",
    "images, depths = load_hdf5_data(image_files, depth_files)\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(images, depths, intrinsics, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 786431 points.\n"
     ]
    }
   ],
   "source": [
    "cloud = point_clouds[0]\n",
    "print(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'point_clouds' contains the list of point cloud objects\n",
    "# Let's say the first element of the list is 'pcd'\n",
    "pcd = point_clouds[0]\n",
    "\n",
    "# Create a visualization window\n",
    "vis = o3d.visualization.Visualizer()\n",
    "\n",
    "# Add the point cloud to the visualization window\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "\n",
    "# Set the render options (optional)\n",
    "render_options = vis.get_render_option()\n",
    "render_options.point_size = 2  # Adjust the size of the points\n",
    "\n",
    "# Render the visualization\n",
    "vis.run()\n",
    "\n",
    "# Close the visualization window\n",
    "vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_point_clouds(point_clouds):\n",
    "    \"\"\"\n",
    "    Merge multiple point clouds into a single point cloud.\n",
    "    \n",
    "    Parameters:\n",
    "        point_clouds (list): List of Open3D PointCloud objects.\n",
    "    \n",
    "    Returns:\n",
    "        combined_pcd (open3d.geometry.PointCloud): Combined point cloud.\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_pcd = o3d.geometry.PointCloud()\n",
    "    for pcd in point_clouds:\n",
    "        combined_pcd += pcd\n",
    "    \n",
    "    return combined_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO Here!\n",
      "Intrinsic Matrix for the scene:\n",
      "[[nan  0. nan]\n",
      " [ 0. nan nan]\n",
      " [ 0.  0.  1.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_point_cloud() missing 1 required positional argument: 'extrinsic_matrices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mdraw_geometries([combined_pcd])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m images, depths \u001b[38;5;241m=\u001b[39m load_hdf5_data(image_files, depth_files)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Generate point clouds for each view\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m point_clouds \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_point_cloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintrinsics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Merge point clouds into a single point cloud\u001b[39;00m\n\u001b[1;32m     31\u001b[0m combined_pcd \u001b[38;5;241m=\u001b[39m merge_point_clouds(point_clouds)\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_point_cloud() missing 1 required positional argument: 'extrinsic_matrices'"
     ]
    }
   ],
   "source": [
    "# Main function to execute the entire pipeline\n",
    "def main():\n",
    "    path_metadata = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds/pointClouds_ChatGPT/metadata_camera_parameters.csv'\n",
    "\n",
    "    base_path = '/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "    scene = 'ai_001_001'  # name of the scene, with format ai_VVV_NNN\n",
    "    cam_xx = 'cam_00'\n",
    "\n",
    "    print(\"TODO Here!\")\n",
    "\n",
    "    # Get list of image and depth HDF5 files\n",
    "    image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "    depth_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.depth_meters.hdf5')))\n",
    "\n",
    "    # Ensure the number of image and depth files match\n",
    "    if len(image_files) != len(depth_files):\n",
    "        raise ValueError(\"The number of image files and depth files do not match.\")\n",
    "\n",
    "    # Get the intrinsic matrix for the scene\n",
    "    intrinsics = get_intrinsics_with_tilt_shift(path_metadata, scene)\n",
    "    print(\"Intrinsic Matrix for the scene:\")\n",
    "    print(intrinsics)\n",
    "\n",
    "    # Load images and depth data\n",
    "    images, depths = load_hdf5_data(image_files, depth_files)\n",
    "\n",
    "    # Generate point clouds for each view\n",
    "    point_clouds = generate_point_cloud(images, depths, intrinsics)\n",
    "\n",
    "    # Merge point clouds into a single point cloud\n",
    "    combined_pcd = merge_point_clouds(point_clouds)\n",
    "\n",
    "    # Save the point cloud to a file\n",
    "    o3d.io.write_point_cloud(\"combined_point_cloud.pcd\", combined_pcd)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([combined_pcd])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisPlayground_pointClouds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
