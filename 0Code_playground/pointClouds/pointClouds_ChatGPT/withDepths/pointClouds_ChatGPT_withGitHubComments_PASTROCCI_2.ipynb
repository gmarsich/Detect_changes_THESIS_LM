{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: thesisPlayground_pointClouds_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints on how to deal with this problem from:\n",
    "- https://github.com/apple/ml-hypersim/issues/9 (source for the code for the conversion Euclidean distance in meters to the optical center of the camera -> distances wrt the plane of the camera)\n",
    "- https://github.com/apple/ml-hypersim/issues/10 (found where to get the conversion asset units <-> meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_file(file_paths, dataset_key):\n",
    "    '''\n",
    "    Load data from HDF5 files given their paths and a dataset key.\n",
    "    This function reads data from HDF5 files specified by `file_paths` and extracts the dataset corresponding to `dataset_key`.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (list of str): List of file paths to HDF5 files.\n",
    "        dataset_key (str): Key to access the dataset within each HDF5 file.\n",
    "\n",
    "    Returns:\n",
    "        data (list of numpy.ndarray): List containing the datasets extracted from each HDF5 file specified by `file_paths`.\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "    for file in file_paths:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(np.array(f[dataset_key]))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def extract_frame_id(filename):\n",
    "    \"\"\"\n",
    "    Extract the frame ID from the filename.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): The filename from which to extract the frame ID, conventions on the name from Hypersim.\n",
    "    \n",
    "    Returns:\n",
    "        int: The extracted frame ID.\n",
    "    \"\"\"\n",
    "    # Split the filename by '.' and take the second part\n",
    "    frame_id_str = filename.split('.')[1]\n",
    "    return int(frame_id_str)\n",
    "\n",
    "\n",
    "\n",
    "def get_depths_oneImage(path_file, path_metadata_scene, intWidth = 1024, intHeight = 768, fltFocal = 886.81): # TODO: understand fltFocal\n",
    "\n",
    "    '''\n",
    "    Processes a dataset containing depth information of an image, and transforms the depth values to be relative to the plane of a camera.\n",
    "    This function reads the depth data from an HDF5 file, whose path is given, gets the depth values for each pixel, and applies a transformation\n",
    "    to obtain the depth values relative to the camera plane.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the HDF5 file containing the dataset with depth information, in meters.\n",
    "    - path_metadata_scene (str): The path to the csv file to get the conversion meters <-> asset units\n",
    "    - intWidth (int, optional): The width of the image in pixels. Default is 1024.\n",
    "    - intHeight (int, optional): The height of the image in pixels. Default is 768.\n",
    "    - fltFocal (float, optional): The focal length of the camera. Default is 886.81.\n",
    "\n",
    "    Returns:\n",
    "    - npyDepths (numpy.ndarray): A 2D numpy array of shape (intHeight, intWidth) containing the depth values for each pixel in the image,\n",
    "        relative to the camera plane. Measures in asset coordinates\n",
    "    '''\n",
    "\n",
    "    data_frame = pd.read_csv(path_metadata_scene)\n",
    "    meters_per_asset_unit = data_frame.loc[data_frame['parameter_name'] == 'meters_per_asset_unit', 'parameter_value'].values[0]\n",
    "\n",
    "\n",
    "    with h5py.File(path_file, 'r') as file:\n",
    "        # Access the dataset and read the data\n",
    "        dataset = file['dataset']\n",
    "        data = dataset[:]\n",
    "        \n",
    "        # Define the list of 2D points (row, column) to get the depth values for\n",
    "        points = [(y, x) for y in range(intHeight) for x in range(intWidth)]\n",
    "        \n",
    "        # Get the depth values for the specified points\n",
    "        npyDistances_array = [data[y, x] for y, x in points]\n",
    "        \n",
    "        # Apply transformation (Euclidean distance in meters to the optical center of the camera -> distances wrt the plane of the camera)\n",
    "        npyImageplaneX = np.linspace((-0.5 * intWidth) + 0.5, (0.5 * intWidth) - 0.5, intWidth).reshape(1, intWidth).repeat(intHeight, 0).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneY = np.linspace((-0.5 * intHeight) + 0.5, (0.5 * intHeight) - 0.5, intHeight).reshape(intHeight, 1).repeat(intWidth, 1).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneZ = np.full([intHeight, intWidth, 1], fltFocal, np.float32)\n",
    "        npyImageplane = np.concatenate([npyImageplaneX, npyImageplaneY, npyImageplaneZ], 2)\n",
    "\n",
    "        npyDistances = np.array(npyDistances_array)\n",
    "        npyDistances = npyDistances.reshape(768, 1024)\n",
    "\n",
    "        npyDepths_meters = npyDistances / np.linalg.norm(npyImageplane, 2, 2) * fltFocal\n",
    "\n",
    "        # Conversion meters -> asset units\n",
    "        npyDepths_assetCoo = npyDepths_meters / meters_per_asset_unit\n",
    "\n",
    "        return npyDepths_assetCoo\n",
    "\n",
    "\n",
    "def get_depths(path_list, path_metadata_scene):\n",
    "    '''\n",
    "    Processes a list of paths to HDF5 files containing depth information.\n",
    "    It iterates through each file path, applies the `get_depths_oneImage` function to obtain the depth values\n",
    "    relative to the camera plane for each image, and collects these depth representations into a list.\n",
    "\n",
    "    Parameters:\n",
    "    - path_list (list of str): A list of file paths to HDF5 files containing depth information.\n",
    "    - path_metadata_scene (str): The path to the csv file to get the conversion meters <-> asset units.\n",
    "\n",
    "    Returns:\n",
    "    - depth_files (list): A list containing representations of depth information for each image in `path_list`, and each element represents an image.\n",
    "        Measures in asset units\n",
    "    '''\n",
    "    \n",
    "    depth_files = []\n",
    "    for i in range(len(path_list)):\n",
    "        depth_files.append(get_depths_oneImage(path_list[i], path_metadata_scene))\n",
    "\n",
    "    return depth_files\n",
    "\n",
    "\n",
    "\n",
    "def get_extrinsics_oneImage(path_positions, path_orientations, frame_id):\n",
    "    \"\"\"\n",
    "    Load camera position and orientation from a HDF5 file and compute the extrinsic matrix for that frame.\n",
    "\n",
    "    Parameters:\n",
    "        path_positions (str): Path to the camera positions HDF5 file. The file contains the data in asset units, not in meters\n",
    "        path_orientations (str): Path to the camera orientations HDF5 file. See https://github.com/apple/ml-hypersim/tree/main?tab=readme-ov-file#camera-trajectories\n",
    "            for more information\n",
    "        frame_id (int): Frame ID to extract the extrinsics for.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The extrinsic matrix [R|t], that is 3x4.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load camera position\n",
    "    with h5py.File(path_positions, \"r\") as f:\n",
    "        camera_positions = f[\"dataset\"][:]\n",
    "    \n",
    "    # Load camera orientation\n",
    "    with h5py.File(path_orientations, \"r\") as f:\n",
    "        camera_orientations = f[\"dataset\"][:]\n",
    "    \n",
    "    # Get position and rotation matrix for the specified frame\n",
    "    camera_position_world = camera_positions[frame_id]\n",
    "    R_world_from_cam = camera_orientations[frame_id]\n",
    "\n",
    "    # Construct the extrinsic matrix [R|t]\n",
    "    extrinsic_matrix = np.hstack((R_world_from_cam, camera_position_world.reshape(3, 1)))\n",
    "    \n",
    "    return extrinsic_matrix\n",
    "\n",
    "\n",
    "def get_extrinsics(path_positions, path_orientations, frames_id):\n",
    "    \"\"\"\n",
    "    Load camera position and orientation from HDF5 files and compute the extrinsic matrix for each frame.\n",
    "\n",
    "    Parameters:\n",
    "        path_positions (str): Path to the camera positions HDF5 file. The file contains the data in asset units, not in meters\n",
    "        path_orientations (str): Path to the camera orientations HDF5 file. See https://github.com/apple/ml-hypersim/tree/main?tab=readme-ov-file#camera-trajectories\n",
    "            for more information\n",
    "        frames_id (list of int): Frames ID to extract the extrinsics for.\n",
    "\n",
    "    Returns:\n",
    "        extrinsics (list of numpy.ndarray): A list containing the extrinsic matrix [R|t] for each frame specified in `frames_id`.\n",
    "            Each extrinsic matrix is a 3x4 transformation matrix representing the camera's position and orientation in the world coordinate system.\n",
    "    \"\"\"\n",
    "    \n",
    "    extrinsics = []\n",
    "    for i in range(len(frames_id)):\n",
    "        extrinsics.append(get_extrinsics_oneImage(path_positions, path_orientations, frames_id[i]))\n",
    "\n",
    "    return extrinsics\n",
    "\n",
    "\n",
    "\n",
    "def get_intrinsics_with_tiltShift(path_metadata, scene_name):\n",
    "    \"\"\"\n",
    "    This function calculates the intrinsic matrix for a camera considering given tilt and shift effects, using metadata from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        path_metadata (str): Path to the metadata CSV file containing camera settings.\n",
    "        scene_name (str): Name of the scene for which the intrinsic matrix is computed.\n",
    "\n",
    "    Returns:\n",
    "        intrinsic_matrix (numpy.ndarray): 3x3 array representing the camera intrinsic matrix. \n",
    "    \"\"\"\n",
    "\n",
    "    # Load the metadata CSV file\n",
    "    df = pd.read_csv(path_metadata)\n",
    "    \n",
    "    # Filter the DataFrame to get the row corresponding to the specified scene\n",
    "    scene_row = df[df['scene_name'] == scene_name]\n",
    "    \n",
    "    if scene_row.empty:\n",
    "        raise ValueError(f\"Scene '{scene_name}' not found in the metadata.\")\n",
    "    \n",
    "    # Use the first matching row\n",
    "    scene_row = scene_row.iloc[0]\n",
    "\n",
    "    # Extract the necessary parameters from the metadata\n",
    "    img_width = scene_row[\"settings_output_img_width\"]\n",
    "    img_height = scene_row[\"settings_output_img_height\"]\n",
    "    focal_length = scene_row[\"camera_physical_focal_length\"]\n",
    "    sensor_width = scene_row[\"camera_physical_film_width\"]\n",
    "\n",
    "    # Calculate fx and fy using the focal length and sensor width\n",
    "    fx = focal_length / sensor_width * img_width\n",
    "    fy = fx  # Assuming square pixels\n",
    "\n",
    "    # Calculate the principal point (cx, cy) considering horizontal and vertical shifts\n",
    "    cx = img_width / 2 + scene_row[\"camera_physical_horizontal_shift\"]\n",
    "    cy = img_height / 2 + scene_row[\"camera_physical_lens_shift\"]\n",
    "\n",
    "    # Construct the intrinsic matrix\n",
    "    intrinsic_matrix = np.array([\n",
    "        [fx, 0, cx],\n",
    "        [0, fy, cy],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    return intrinsic_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_point_cloud(depth_image, intrinsic_matrix, extrinsic_matrix):\n",
    "    \"\"\"\n",
    "    Generate a point cloud from a depth image, intrinsic matrix, and extrinsic matrix.\n",
    "\n",
    "    Parameters:\n",
    "        depth_image (np.ndarray): Depth image with distances from the camera plane.\n",
    "        intrinsic_matrix (np.ndarray): Intrinsic matrix of the camera.\n",
    "        extrinsic_matrix (np.ndarray): Extrinsic matrix of the camera [R|t].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Point cloud in world coordinates, shape (N, 3) where N is the number of points.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the depth image\n",
    "    height, width = depth_image.shape\n",
    "    \n",
    "    # Create a grid of (u, v) coordinates\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    \n",
    "    # Flatten the u, v coordinates and depth image\n",
    "    u_flat = u.flatten()\n",
    "    v_flat = v.flatten()\n",
    "    depth_flat = depth_image.flatten()\n",
    "    \n",
    "    # Compute the 3D coordinates in the camera frame\n",
    "    fx = intrinsic_matrix[0, 0]\n",
    "    fy = intrinsic_matrix[1, 1]\n",
    "    cx = intrinsic_matrix[0, 2]\n",
    "    cy = intrinsic_matrix[1, 2]\n",
    "    \n",
    "    x = (u_flat - cx) * depth_flat / fx\n",
    "    y = (v_flat - cy) * depth_flat / fy\n",
    "    z = depth_flat\n",
    "    \n",
    "    # Stack the 3D points in camera coordinates\n",
    "    points_camera = np.vstack((x, y, z, np.ones_like(x)))\n",
    "    \n",
    "    # Transform points to world coordinates using the extrinsic matrix\n",
    "    points_world = extrinsic_matrix @ points_camera\n",
    "    \n",
    "    # Drop the homogeneous coordinate\n",
    "    points_world = points_world[:3, :].T\n",
    "    \n",
    "    return points_world\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def render_point_cloud(point_cloud):\n",
    "    # Create Open3D point cloud object\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud.reshape(-1, 3))  # Reshape the array to 3D points\n",
    "\n",
    "    # Create Open3D visualizer object\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "\n",
    "    # Add the point cloud to the visualization window\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set the render options (optional)\n",
    "    render_options = vis.get_render_option()\n",
    "    render_options.point_size = 1.0  # Adjust point size if needed\n",
    "\n",
    "    # Run the visualizer\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metadata = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds/pointClouds_ChatGPT/withDepths/metadata_camera_parameters.csv'\n",
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_007_008'  # name of the scene, with format ai_VVV_NNN\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "# Get list of image and depth HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "depthEuclidean_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.depth_meters.hdf5')))\n",
    "\n",
    "positions_path = os.path.join(base_path, scene, '_detail', cam_xx, 'camera_keyframe_positions.hdf5')\n",
    "orientation_path = os.path.join(base_path, scene, '_detail', cam_xx, 'camera_keyframe_orientations.hdf5')\n",
    "\n",
    "# Ensure the number of image and depth files match\n",
    "if len(image_files) != len(depthEuclidean_files):\n",
    "    raise ValueError(\"The number of image files and depth files do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_width:  1024.0\n",
      "camera_physical_horizontal_shift\": 0.0\n",
      "img_height :  768.0\n",
      "camera_physical_lens_shift\": -0.0799999982118606\n",
      "Intrinsic Matrix for the scene:\n",
      "[[1.43810735e+03 0.00000000e+00 5.12000000e+02]\n",
      " [0.00000000e+00 1.43810735e+03 3.83920000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Extrinsics Matrix for the scene:\n",
      "[[ 9.99448895e-01  2.52561085e-03 -3.30993086e-02  7.81024837e+00]\n",
      " [-3.31955254e-02  7.60409459e-02 -9.96551991e-01 -2.44333206e+02]\n",
      " [ 0.00000000e+00  9.97101486e-01  7.60828778e-02  4.44449768e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Load images data\n",
    "images = load_hdf5_file(image_files, 'dataset')\n",
    "\n",
    "# Get the intrinsic matrix for the scene\n",
    "intrinsics = get_intrinsics_with_tilt_shift_inputScene(path_metadata, scene)\n",
    "print(\"Intrinsic Matrix for the scene:\")\n",
    "print(intrinsics)\n",
    "\n",
    "# Get the extrinsics matrix for the scene\n",
    "depthEuclidean_files_id = [extract_frame_id(os.path.basename(file)) for file in depthEuclidean_files]\n",
    "extrinsics = get_extrinsics(positions_path, orientation_path, depthEuclidean_files_id)\n",
    "print(\"Extrinsics Matrix for the scene:\")\n",
    "print(extrinsics[0])\n",
    "\n",
    "# Get the depths from the plane (and not the distances from the camera)\n",
    "depth_files = get_depths(depthEuclidean_files)\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(depth_files[0], intrinsics, extrinsics)\n",
    "\n",
    "\n",
    "# render_point_cloud(point_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_point_cloud(point_clouds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisPlayground_pointClouds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
