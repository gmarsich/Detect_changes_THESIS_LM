{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: thesisPlayground_pointClouds_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints on how to deal with this problem from:\n",
    "- https://github.com/apple/ml-hypersim/issues/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metadata_camera_parameters = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds_Hypersim/withDepths/metadata_camera_parameters.csv'\n",
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes'\n",
    "scene = 'ai_001_001'  # name of the scene, with format ai_VVV_NNN\n",
    "cam_xx = 'cam_00'\n",
    "\n",
    "# Get list of image and depth HDF5 files\n",
    "image_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', '*.color.hdf5')))\n",
    "depthEuclidean_files = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.depth_meters.hdf5')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0253999996930359996094583863168736570514738559722900390625\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal, getcontext\n",
    "\n",
    "def get_metadata(path_metadata_camera_parameters, scene):\n",
    "    # Load the metadata CSV file\n",
    "    df = pd.read_csv(path_metadata_camera_parameters)\n",
    "    \n",
    "    # Filter the DataFrame to get the row corresponding to the specified scene\n",
    "    scene_row = df[df['scene_name'] == scene]\n",
    "\n",
    "    return scene_row\n",
    "\n",
    "# Set the precision for the decimal module\n",
    "getcontext().prec = 50\n",
    "\n",
    "scene_row = get_metadata(path_metadata_camera_parameters, scene)\n",
    "\n",
    "# Extract the specific column value\n",
    "column_value = scene_row['settings_units_info_meters_scale'].values[0]\n",
    "\n",
    "# Convert to Decimal for highest precision\n",
    "decimal_value = Decimal(column_value)\n",
    "\n",
    "# Print the entire number with full precision\n",
    "print(decimal_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depths_oneImage(path_file_depths, intWidth = 1024, intHeight = 768, fltFocal = 886.81, factor_assets_to_meters = 0.025399999693035999609458386316873657):\n",
    "\n",
    "    with h5py.File(path_file_depths, 'r') as file:\n",
    "        # Access the dataset\n",
    "        dataset = file['dataset']\n",
    "        \n",
    "        # Read the data from the dataset\n",
    "        data = dataset[:] # len(data) is 768, len(data[0]) is 1024, data[0][0] is the value of the depth\n",
    "\n",
    "        npyImageplaneX = np.linspace((-0.5 * intWidth) + 0.5, (0.5 * intWidth) - 0.5, intWidth).reshape(1, intWidth).repeat(intHeight, 0).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneY = np.linspace((-0.5 * intHeight) + 0.5, (0.5 * intHeight) - 0.5, intHeight).reshape(intHeight, 1).repeat(intWidth, 1).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneZ = np.full([intHeight, intWidth, 1], fltFocal, np.float32)\n",
    "        npyImageplane = np.concatenate([npyImageplaneX, npyImageplaneY, npyImageplaneZ], 2)\n",
    "\n",
    "        npyDepth_meters = data / np.linalg.norm(npyImageplane, 2, 2) * fltFocal\n",
    "\n",
    "        npyDepth_assets = npyDepth_meters / factor_assets_to_meters\n",
    "\n",
    "        return npyDepth_assets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_point_cloud(files_depths):\n",
    "\n",
    "    width_pixels = 1024 # TODO maybe should be a parameter\n",
    "    height_pixels = 768 # TODO maybe should be a parameter\n",
    "\n",
    "    fx = 886.81 # TODO maybe should be a parameter\n",
    "    fy = fx\n",
    "\n",
    "    point_clouds = []\n",
    "\n",
    "    for depths in files_depths:\n",
    "\n",
    "        cam_coo = []\n",
    "\n",
    "        for y in range(height_pixels):\n",
    "            for x in range(width_pixels):\n",
    "                z_cam = - depths[y][x] # the - is because of the coordinate system\n",
    "                x_cam = (x - width_pixels/2) / fx * (-z_cam) \n",
    "                y_cam = -(y - height_pixels/2) / fy * (-z_cam) # TODO maybe something to change the coordinates should be done\n",
    "                xyz_cam = [x_cam, y_cam, z_cam] # if you multiply z_cam0 by 1000 the rendering is a little bit nicer\n",
    "\n",
    "                cam_coo.append(xyz_cam)\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(cam_coo)\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "\n",
    "    return point_clouds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT THING TO DO: create a new generate_point_cloud(files_depths) that gets in input also the extrinsics matrix. This new function will have to construct the point cloud in the world-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_files = get_depths_oneImage(depthEuclidean_files[2])\n",
    "depth_files_list = [depth_files]\n",
    "\n",
    "point_clouds = generate_point_cloud(depth_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(point_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([point_clouds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depths(path_list):\n",
    "    '''Each element of depth_files will be a representation of an image'''\n",
    "    \n",
    "    depth_files = []\n",
    "    for i in range(path_list):\n",
    "        depth_files[i] = get_depths_oneImage(path_list[i])\n",
    "\n",
    "    return depth_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsics_from_metadata_COMPLETE(path_metadata, scene_row):\n",
    "    \"\"\"\n",
    "    Load camera metadata from a CSV file and compute the intrinsic matrix considering tilt-shift parameters.\n",
    "\n",
    "    Parameters:\n",
    "        path_metadata (str): Path to the metadata CSV file.\n",
    "        scene_name (str): Name of the scene to analyze.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The updated intrinsic matrix K.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the metadata CSV file\n",
    "    df = pd.read_csv(path_metadata)\n",
    "    \n",
    "    # Filter the DataFrame to get the row corresponding to the specified scene\n",
    "    scene_row = df[df['scene_name'] == scene_row]\n",
    "    \n",
    "    if scene_row.empty:\n",
    "        raise ValueError(f\"Scene '{scene_row}' not found in the metadata.\")\n",
    "    \n",
    "    # Use the first matching row\n",
    "    scene_row = scene_row.iloc[0]\n",
    "\n",
    "    # Extract the necessary parameters from the metadata\n",
    "    img_width = scene_row[\"settings_output_img_width\"]\n",
    "    img_height = scene_row[\"settings_output_img_height\"]\n",
    "    focal_length = scene_row[\"camera_physical_focal_length\"] # remark that it's in millimeters\n",
    "    sensor_width = scene_row[\"camera_physical_film_width\"] # remark that it's in millimeters\n",
    "\n",
    "    # Calculate fx and fy using the focal length and sensor width\n",
    "    fx = focal_length / sensor_width * img_width # conversion mm -> pixels\n",
    "    fy = fx  # Assuming square pixels\n",
    "\n",
    "    # Calculate the principal point (cx, cy) considering horizontal and vertical shifts\n",
    "    cx = img_width / 2 # TODO FOR TILT-SHIFT should add: + scene_row[\"camera_physical_horizontal_shift\"] but I am not sure about the unit of measure\n",
    "    print('img_width: ', img_width)\n",
    "    print('camera_physical_horizontal_shift\":', scene_row[\"camera_physical_horizontal_shift\"])\n",
    "    cy = img_height / 2 # TODO FOR TILT-SHIFT should add: + scene_row[\"camera_physical_lens_shift\"] but I am not sure about the unit of measure\n",
    "    print('img_height : ', img_height )\n",
    "    print('camera_physical_lens_shift\":', scene_row[\"camera_physical_lens_shift\"])\n",
    "\n",
    "    # Construct the intrinsic matrix. Everything is in pixels\n",
    "    intrinsic_matrix = np.array([\n",
    "        [fx, 0, cx],\n",
    "        [0, fy, cy],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    return intrinsic_matrix\n",
    "\n",
    "\n",
    "\n",
    "def load_hdf5_data(image_files, depth_files):\n",
    "    \"\"\"\n",
    "    Load images and depth data from multiple HDF5 files.\n",
    "    \n",
    "    Parameters:\n",
    "        image_files (list): List of paths to the HDF5 files containing images.\n",
    "        depth_files (list): List of paths to the HDF5 files containing depth maps.\n",
    "    \n",
    "    Returns:\n",
    "        images (list): List of images.\n",
    "        depths (list): List of depth maps.\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    depths = []\n",
    "\n",
    "    for image_file, depth_file in zip(image_files, depth_files):\n",
    "        with h5py.File(image_file, 'r') as f:\n",
    "            images.append(np.array(f['dataset']))  # Adjust the key according to your HDF5 structure\n",
    "\n",
    "        with h5py.File(depth_file, 'r') as f:\n",
    "            depths.append(np.array(f['dataset']))  # Adjust the key according to your HDF5 structure\n",
    "\n",
    "    return images, depths\n",
    "\n",
    "\n",
    "\n",
    "def generate_point_cloud_OLD(images, depths, intrinsic_matrix): # extrinsic_matrices is not useful here, but will be used afterwards, having more images to put together\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        images (list): List of images.\n",
    "        depths (list): List of depth maps.\n",
    "        intrinsic_matrix (np.ndarray): Intrinsic matrix of the camera.\n",
    "\n",
    "    Returns:\n",
    "        point_clouds (list): List of Open3D PointCloud objects.\n",
    "    \"\"\"\n",
    "    point_clouds = []\n",
    "\n",
    "    for image, depth in zip(images, depths):\n",
    "\n",
    "        # Get the image dimensions\n",
    "        h, w = depth.shape\n",
    "\n",
    "        # Create a mesh grid of pixel coordinates\n",
    "        u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "        u = u.flatten()\n",
    "        v = v.flatten()\n",
    "\n",
    "        # Get the corresponding depth values\n",
    "        z = depth.flatten()\n",
    "\n",
    "        # Filter out points with zero depth\n",
    "        valid = z > 0\n",
    "        u = u[valid]\n",
    "        v = v[valid]\n",
    "        z = z[valid]\n",
    "\n",
    "        # Convert pixel coordinates to normalized image coordinates; create 3D points in the camera coordinate system\n",
    "        x = (u - intrinsic_matrix[0, 2]) / intrinsic_matrix[0, 0] * z\n",
    "        y = (v - intrinsic_matrix[1, 2]) / intrinsic_matrix[1, 1] * z\n",
    "\n",
    "        # Stack the coordinates into a single array\n",
    "        points = np.vstack((x, y, z)).T\n",
    "\n",
    "\n",
    "        # The commented things will be useful when dealing with more than one image\n",
    "\n",
    "        # # Apply extrinsic transformation\n",
    "        # ones = np.ones((points.shape[0], 1))\n",
    "        # points_homogeneous = np.hstack((points, ones))\n",
    "        # points_transformed = (extrinsic_matrix @ points_homogeneous.T).T[:, :3]\n",
    "\n",
    "        # Create Open3D PointCloud object and add it to the list\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        #pcd.points = o3d.utility.Vector3dVector(points_transformed)\n",
    "        pcd.points = o3d.utility.Vector3dVector(points) # to be deleted when having more than one image\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "def generate_point_cloud(images, depths, intrinsic_matrix):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        images (list): List of images.\n",
    "        depths (list): List of depth maps.\n",
    "        intrinsic_matrix (np.ndarray): Intrinsic matrix of the camera.\n",
    "\n",
    "    Returns:\n",
    "        point_clouds (list): List of Open3D PointCloud objects.\n",
    "    \"\"\"\n",
    "    point_clouds = []\n",
    "\n",
    "    for image, depth in zip(images, depths):\n",
    "\n",
    "        # Get the image dimensions\n",
    "        h, w = depth.shape\n",
    "\n",
    "        # Create a mesh grid of pixel coordinates\n",
    "        u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "        u = u.flatten()\n",
    "        v = v.flatten()\n",
    "\n",
    "        # Get the corresponding depth values\n",
    "        z = depth.flatten()\n",
    "\n",
    "        # Filter out points with zero depth\n",
    "        valid = z > 0\n",
    "        u = u[valid]\n",
    "        v = v[valid]\n",
    "        z = z[valid]\n",
    "\n",
    "        # Convert pixel coordinates to normalized image coordinates; create 3D points in the camera coordinate system\n",
    "        x = (u - intrinsic_matrix[0, 2]) / intrinsic_matrix[0, 0] * z\n",
    "        y = (v - intrinsic_matrix[1, 2]) / intrinsic_matrix[1, 1] * z\n",
    "\n",
    "        # Stack the coordinates into a single array\n",
    "        points = np.vstack((x, y, z)).T\n",
    "\n",
    "\n",
    "        # The commented things will be useful when dealing with more than one image\n",
    "\n",
    "        # # Apply extrinsic transformation\n",
    "        # ones = np.ones((points.shape[0], 1))\n",
    "        # points_homogeneous = np.hstack((points, ones))\n",
    "        # points_transformed = (extrinsic_matrix @ points_homogeneous.T).T[:, :3]\n",
    "\n",
    "        # Create Open3D PointCloud object and add it to the list\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        #pcd.points = o3d.utility.Vector3dVector(points_transformed)\n",
    "        pcd.points = o3d.utility.Vector3dVector(points) # to be deleted when having more than one image\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "\n",
    "def render_point_cloud(point_cloud):\n",
    "\n",
    "    pcd = point_cloud\n",
    "\n",
    "    # Create a visualization window\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "\n",
    "    # Add the point cloud to the visualization window\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set the render options (optional)\n",
    "    render_options = vis.get_render_option()\n",
    "    render_options.point_size = 2  # Adjust the size of the points\n",
    "\n",
    "    # Render the visualization\n",
    "    vis.run()\n",
    "\n",
    "    # Close the visualization window\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Ensure the number of image and depth files match\n",
    "# if len(image_files) != len(depth_files):\n",
    "#     raise ValueError(\"The number of image files and depth files do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_intrinsics_with_tilt_shift_COMPLETE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the intrinsic matrix for the scene\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m intrinsics \u001b[38;5;241m=\u001b[39m \u001b[43mget_intrinsics_with_tilt_shift_COMPLETE\u001b[49m(path_metadata, scene)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntrinsic Matrix for the scene:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(intrinsics)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_intrinsics_with_tilt_shift_COMPLETE' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the intrinsic matrix for the scene\n",
    "intrinsics = get_intrinsics_with_tilt_shift_COMPLETE(path_metadata, scene)\n",
    "print(\"Intrinsic Matrix for the scene:\")\n",
    "print(intrinsics)\n",
    "\n",
    "# Load images and depth data\n",
    "images, file_depths = load_hdf5_data(image_files, position_files)\n",
    "\n",
    "# Generate point clouds for each view\n",
    "point_clouds = generate_point_cloud(images, file_depths, intrinsics, 1) # here extrinsics_matrices = 1 because it is not used, the value 1 is random\n",
    "\n",
    "cloud = point_clouds[0]\n",
    "print(cloud)\n",
    "\n",
    "render_point_cloud(point_clouds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisPlayground_pointClouds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
