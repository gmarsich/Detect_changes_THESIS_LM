{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: thesisPlayground_pointClouds_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using depths - Point cloud from more images using the world-space\n",
    "### Colour given by default by the height from the floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints on how to deal with this problem from:\n",
    "- https://github.com/apple/ml-hypersim/issues/9\n",
    "- https://github.com/apple/ml-hypersim/issues/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depths_oneImage(path_file_depths, intWidth, intHeight, factor_assets_to_meters, fltFocal):\n",
    "\n",
    "    with h5py.File(path_file_depths, 'r') as file:\n",
    "\n",
    "        dataset = file['dataset']\n",
    "        data = dataset[:] # len(data) is 768, len(data[0]) is 1024, data[0][0] is the value of the depth\n",
    "\n",
    "        # Transform the distances from the optical center of the camera to depths (distance from the plane passing by the optical center)\n",
    "        npyImageplaneX = np.linspace((-0.5 * intWidth) + 0.5, (0.5 * intWidth) - 0.5, intWidth).reshape(1, intWidth).repeat(intHeight, 0).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneY = np.linspace((-0.5 * intHeight) + 0.5, (0.5 * intHeight) - 0.5, intHeight).reshape(intHeight, 1).repeat(intWidth, 1).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneZ = np.full([intHeight, intWidth, 1], fltFocal, np.float32)\n",
    "        npyImageplane = np.concatenate([npyImageplaneX, npyImageplaneY, npyImageplaneZ], 2)\n",
    "\n",
    "        npyDepth_meters = data / np.linalg.norm(npyImageplane, 2, 2) * fltFocal\n",
    "\n",
    "        # Convert from meters to asset units\n",
    "        npyDepth_assets = npyDepth_meters / factor_assets_to_meters\n",
    "\n",
    "        return npyDepth_assets\n",
    "    \n",
    "\n",
    "def get_focalLength(path_metadata_camera_parameters, scene):\n",
    "\n",
    "    df_camera_parameters = pd.read_csv(path_metadata_camera_parameters, index_col=\"scene_name\")\n",
    "    df_ = df_camera_parameters.loc[scene]\n",
    "\n",
    "    intWidth = int(df_[\"settings_output_img_width\"])\n",
    "    fov = math.pi/3.0\n",
    "    focal_length_pixels = intWidth/(2 * math.tan(fov/2))\n",
    "\n",
    "    return focal_length_pixels\n",
    "\n",
    "\n",
    "def get_depths(path_list_depths, path_metadata_camera_parameters, scene):\n",
    "    \n",
    "    # Get the useful parameters from path_metadata_camera_parameters\n",
    "    df_camera_parameters = pd.read_csv(path_metadata_camera_parameters, index_col=\"scene_name\")\n",
    "    df_ = df_camera_parameters.loc[scene]\n",
    "\n",
    "    intWidth = int(df_[\"settings_output_img_width\"])\n",
    "    intHeight = int(df_[\"settings_output_img_height\"])\n",
    "    factor_assets_to_meters = df_[\"settings_units_info_meters_scale\"]\n",
    "\n",
    "    # Depending on the scene, a default value for the focal length may be assumed or not\n",
    "    focal_length_pixels = get_focalLength(path_metadata_camera_parameters, scene)\n",
    "\n",
    "    # Get the depths files for each image\n",
    "    depth_files = []\n",
    "    for i in range(len(path_list_depths)):\n",
    "        depth_files.append(get_depths_oneImage(path_list_depths[i], intWidth, intHeight, factor_assets_to_meters, focal_length_pixels))\n",
    "\n",
    "    return depth_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_ids(paths_filenames):\n",
    "    \"\"\"\n",
    "    Extracts frame IDs from a list of filenames.\n",
    "    \n",
    "    Parameters:\n",
    "        paths_filenames (list): List of file paths. Last info of a path is the filename.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of extracted frame IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    frame_ids = []\n",
    "    for path_filename in paths_filenames:\n",
    "        filename = path_filename.split('/')[-1]  # Extracting just the filename from the path\n",
    "        frame_id_str = filename.split('.')[1]\n",
    "        frame_id = int(frame_id_str)\n",
    "        frame_ids.append(frame_id)\n",
    "\n",
    "    return frame_ids\n",
    "\n",
    "\n",
    "def get_extrinsics_oneImage(path_positions, path_orientations, frame_id):\n",
    "    \"\"\"\n",
    "    Load camera position and orientation from HDF5 files and compute the extrinsic matrix.\n",
    "\n",
    "    Parameters:\n",
    "        path_position (str): Path to the camera positions HDF5 file.\n",
    "        path_orientation (str): Path to the camera orientations HDF5 file.\n",
    "        frame_id (int): Frame ID to extract the extrinsics for.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The extrinsic matrix [R|t].\n",
    "    \"\"\"\n",
    "\n",
    "    # Load camera position\n",
    "    with h5py.File(path_positions, \"r\") as f:\n",
    "        camera_positions = f[\"dataset\"][:]\n",
    "    \n",
    "    # Load camera orientation\n",
    "    with h5py.File(path_orientations, \"r\") as f:\n",
    "        camera_orientations = f[\"dataset\"][:]\n",
    "    \n",
    "    # Get position and rotation matrix for the specified frame\n",
    "    camera_position_world = camera_positions[frame_id]\n",
    "    R_world_from_cam = camera_orientations[frame_id]\n",
    "\n",
    "    # Construct the extrinsic matrix [R|t]\n",
    "    extrinsic_matrix = np.hstack((R_world_from_cam, camera_position_world.reshape(3, 1)))\n",
    "    \n",
    "    return extrinsic_matrix\n",
    "\n",
    "\n",
    "def get_extrinsics(path_positions, path_orientations, frames_ids):\n",
    "    extrinsics_matrices = []\n",
    "    for i in range(len(frames_ids)):\n",
    "        extrinsics_matrices.append(get_extrinsics_oneImage(path_positions, path_orientations, frames_ids[i]))\n",
    "\n",
    "    return extrinsics_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_point_cloud(files_depths, extrinsics_matrices, path_metadata_camera_parameters, scene):\n",
    "\n",
    "    df_camera_parameters = pd.read_csv(path_metadata_camera_parameters, index_col=\"scene_name\")\n",
    "    df_ = df_camera_parameters.loc[scene]\n",
    "\n",
    "    intWidth = int(df_[\"settings_output_img_width\"])\n",
    "    intHeight = int(df_[\"settings_output_img_height\"])\n",
    "\n",
    "    fx = get_focalLength(path_metadata_camera_parameters, scene)\n",
    "    fy = fx\n",
    "\n",
    "    point_clouds = []\n",
    "\n",
    "    for i in range(len(files_depths)):\n",
    "        depths = files_depths[i]\n",
    "        world_coo = []\n",
    "\n",
    "        for y in range(intHeight):\n",
    "            for x in range(intWidth):\n",
    "                z_cam = - depths[y][x] # the - is because of the coordinate system\n",
    "                x_cam = (x - intWidth/2) / fx * (-z_cam) \n",
    "                y_cam = -(y - intHeight/2) / fy * (-z_cam)\n",
    "                xyz_cam = np.array([x_cam, y_cam, z_cam])\n",
    "                xyz_cam_One = np.append(xyz_cam, 1)\n",
    "\n",
    "                world_coordinates = np.dot(extrinsics_matrices[i], xyz_cam_One.reshape(4, 1)).flatten()\n",
    "                world_coo.append(world_coordinates)\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(world_coo)\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "def merge_point_clouds(point_clouds):\n",
    "    \"\"\"\n",
    "    Merges multiple Open3D PointCloud objects into a single PointCloud object.\n",
    "\n",
    "    Parameters:\n",
    "        point_clouds (list of o3d.geometry.PointCloud): A list of Open3D PointCloud objects.\n",
    "\n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: A single Open3D PointCloud object containing the merged 3D coordinates of all point clouds.\n",
    "    \"\"\"\n",
    "    # Create an empty Open3D PointCloud object to store the merged point cloud\n",
    "    merged_point_cloud = o3d.geometry.PointCloud()\n",
    "    \n",
    "    # Concatenate all the individual point clouds into a single point cloud\n",
    "    for pcd in point_clouds:\n",
    "        merged_point_cloud += pcd\n",
    "    \n",
    "    return merged_point_cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metadata_camera_parameters = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds_Hypersim/withDepths/metadata_camera_parameters.csv' # TODO TOSET: change with what you need\n",
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes' # TODO TOSET: change with what you need\n",
    "scene = 'ai_001_001'  # name of the scene, with format ai_VVV_NNN # TODO TOSET: change with what you need\n",
    "cam_xx = 'cam_00' # TODO TOSET: change with what you need\n",
    "\n",
    "# Get list of depth HDF5 files\n",
    "paths_depthEuclidean = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.depth_meters.hdf5')))\n",
    "\n",
    "# Get orientations and positions\n",
    "paths_orientations = os.path.join(base_path, scene, '_detail', cam_xx, 'camera_keyframe_orientations.hdf5')\n",
    "paths_positions = os.path.join(base_path, scene, '_detail', cam_xx, 'camera_keyframe_positions.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_files = get_depths(paths_depthEuclidean, path_metadata_camera_parameters, scene)\n",
    "\n",
    "frames_ids = extract_frames_ids(paths_depthEuclidean)\n",
    "extrinsics_matrices = get_extrinsics(paths_positions, paths_orientations, frames_ids)\n",
    "print(extrinsics_matrices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_clouds = generate_point_cloud(depth_files, extrinsics_matrices, path_metadata_camera_parameters, scene)\n",
    "merged_point_clouds = merge_point_clouds(point_clouds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([merged_point_clouds]) # to visualise the point cloud\n",
    "# o3d.io.write_point_cloud(\"point_cloud_DEPTHS.ply\", merged_point_clouds) # to save the point cloud as .ply file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to open a point cloud\n",
    "# pcd = o3d.io.read_point_cloud(\"/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds_Hypersim/point_cloud.ply\")\n",
    "# render_point_cloud(pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using depths - Point cloud from more images using the world-space\n",
    "### Colour given by a tonemapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one first needs to preprocess the `*color.hdf5 files`, applying a tonemap. I considered the same tonemap as the one used by Hypersim (and described in this code: https://github.com/apple/ml-hypersim/blob/main/code/python/tools/scene_generate_images_tonemap.py). I created a file `apply_tonemap.py` that converts `.color.hdf5` files into hdf5 files with the tonemap, and saves them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depths_oneImage(path_file_depths, intWidth, intHeight, factor_assets_to_meters, fltFocal):\n",
    "\n",
    "    with h5py.File(path_file_depths, 'r') as file:\n",
    "\n",
    "        dataset = file['dataset']\n",
    "        data = dataset[:] # len(data) is 768, len(data[0]) is 1024, data[0][0] is the value of the depth\n",
    "\n",
    "        # Transform the distances from the optical center of the camera to depths (distance from the plane passing by the optical center)\n",
    "        npyImageplaneX = np.linspace((-0.5 * intWidth) + 0.5, (0.5 * intWidth) - 0.5, intWidth).reshape(1, intWidth).repeat(intHeight, 0).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneY = np.linspace((-0.5 * intHeight) + 0.5, (0.5 * intHeight) - 0.5, intHeight).reshape(intHeight, 1).repeat(intWidth, 1).astype(np.float32)[:, :, None]\n",
    "        npyImageplaneZ = np.full([intHeight, intWidth, 1], fltFocal, np.float32)\n",
    "        npyImageplane = np.concatenate([npyImageplaneX, npyImageplaneY, npyImageplaneZ], 2)\n",
    "\n",
    "        npyDepth_meters = data / np.linalg.norm(npyImageplane, 2, 2) * fltFocal\n",
    "\n",
    "        # Convert from meters to asset units\n",
    "        npyDepth_assets = npyDepth_meters / factor_assets_to_meters\n",
    "\n",
    "        return npyDepth_assets\n",
    "    \n",
    "\n",
    "def get_focalLength(path_metadata_camera_parameters, scene):\n",
    "\n",
    "    df_camera_parameters = pd.read_csv(path_metadata_camera_parameters, index_col=\"scene_name\")\n",
    "    df_ = df_camera_parameters.loc[scene]\n",
    "\n",
    "    intWidth = int(df_[\"settings_output_img_width\"])\n",
    "    fov = math.pi/3.0\n",
    "    focal_length_pixels = intWidth/(2 * math.tan(fov/2))\n",
    "\n",
    "    return focal_length_pixels\n",
    "\n",
    "\n",
    "def get_depths(path_list_depths, path_metadata_camera_parameters, scene):\n",
    "    \n",
    "    # Get the useful parameters from path_metadata_camera_parameters\n",
    "    df_camera_parameters = pd.read_csv(path_metadata_camera_parameters, index_col=\"scene_name\")\n",
    "    df_ = df_camera_parameters.loc[scene]\n",
    "\n",
    "    intWidth = int(df_[\"settings_output_img_width\"])\n",
    "    intHeight = int(df_[\"settings_output_img_height\"])\n",
    "    factor_assets_to_meters = df_[\"settings_units_info_meters_scale\"]\n",
    "\n",
    "    # Depending on the scene, a default value for the focal length may be assumed or not\n",
    "    focal_length_pixels = get_focalLength(path_metadata_camera_parameters, scene)\n",
    "\n",
    "    # Get the depths files for each image\n",
    "    depth_files = []\n",
    "    for i in range(len(path_list_depths)):\n",
    "        depth_files.append(get_depths_oneImage(path_list_depths[i], intWidth, intHeight, factor_assets_to_meters, focal_length_pixels))\n",
    "\n",
    "    return depth_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_ids(paths_filenames):\n",
    "    \"\"\"\n",
    "    Extracts frame IDs from a list of filenames.\n",
    "    \n",
    "    Parameters:\n",
    "        paths_filenames (list): List of file paths. Last info of a path is the filename.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of extracted frame IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    frame_ids = []\n",
    "    for path_filename in paths_filenames:\n",
    "        filename = path_filename.split('/')[-1]  # Extracting just the filename from the path\n",
    "        frame_id_str = filename.split('.')[1]\n",
    "        frame_id = int(frame_id_str)\n",
    "        frame_ids.append(frame_id)\n",
    "\n",
    "    return frame_ids\n",
    "\n",
    "\n",
    "def get_extrinsics_oneImage(path_positions, path_orientations, frame_id):\n",
    "    \"\"\"\n",
    "    Load camera position and orientation from HDF5 files and compute the extrinsic matrix.\n",
    "\n",
    "    Parameters:\n",
    "        path_position (str): Path to the camera positions HDF5 file.\n",
    "        path_orientation (str): Path to the camera orientations HDF5 file.\n",
    "        frame_id (int): Frame ID to extract the extrinsics for.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The extrinsic matrix [R|t].\n",
    "    \"\"\"\n",
    "\n",
    "    # Load camera position\n",
    "    with h5py.File(path_positions, \"r\") as f:\n",
    "        camera_positions = f[\"dataset\"][:]\n",
    "    \n",
    "    # Load camera orientation\n",
    "    with h5py.File(path_orientations, \"r\") as f:\n",
    "        camera_orientations = f[\"dataset\"][:]\n",
    "    \n",
    "    # Get position and rotation matrix for the specified frame\n",
    "    camera_position_world = camera_positions[frame_id]\n",
    "    R_world_from_cam = camera_orientations[frame_id]\n",
    "\n",
    "    # Construct the extrinsic matrix [R|t]\n",
    "    extrinsic_matrix = np.hstack((R_world_from_cam, camera_position_world.reshape(3, 1)))\n",
    "    \n",
    "    return extrinsic_matrix\n",
    "\n",
    "\n",
    "def get_extrinsics(path_positions, path_orientations, frames_ids):\n",
    "    extrinsics_matrices = []\n",
    "    for i in range(len(frames_ids)):\n",
    "        extrinsics_matrices.append(get_extrinsics_oneImage(path_positions, path_orientations, frames_ids[i]))\n",
    "\n",
    "    return extrinsics_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_point_cloud(paths_images, files_depths, extrinsics_matrices, path_metadata_camera_parameters, scene):\n",
    "\n",
    "    images = []\n",
    "    for image in paths_images:\n",
    "        with h5py.File(image, 'r') as f:\n",
    "            images.append(np.array(f['tonemapped_rgb']))\n",
    "\n",
    "    df_camera_parameters = pd.read_csv(path_metadata_camera_parameters, index_col=\"scene_name\")\n",
    "    df_ = df_camera_parameters.loc[scene]\n",
    "\n",
    "    intWidth = int(df_[\"settings_output_img_width\"])\n",
    "    intHeight = int(df_[\"settings_output_img_height\"])\n",
    "\n",
    "    fx = get_focalLength(path_metadata_camera_parameters, scene)\n",
    "    fy = fx\n",
    "\n",
    "    point_clouds = []\n",
    "\n",
    "    for i in range(len(files_depths)):\n",
    "\n",
    "        # Extracting color information from images\n",
    "        image = images[i]\n",
    "        R = image[:, :, 0]\n",
    "        G = image[:, :, 1]\n",
    "        B = image[:, :, 2]\n",
    "        colors = np.stack((R, G, B), axis=-1) # stack R, G, B to get point cloud colors\n",
    "\n",
    "\n",
    "        depths = files_depths[i]\n",
    "        world_coo = []\n",
    "\n",
    "        for y in range(intHeight):\n",
    "            for x in range(intWidth):\n",
    "                z_cam = - depths[y][x] # the - is because of the coordinate system\n",
    "                x_cam = (x - intWidth/2) / fx * (-z_cam) \n",
    "                y_cam = -(y - intHeight/2) / fy * (-z_cam)\n",
    "                xyz_cam = np.array([x_cam, y_cam, z_cam])\n",
    "                xyz_cam_One = np.append(xyz_cam, 1)\n",
    "\n",
    "                world_coordinates = np.dot(extrinsics_matrices[i], xyz_cam_One.reshape(4, 1)).flatten()\n",
    "                world_coo.append(world_coordinates)\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(world_coo)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors.reshape(-1, 3))\n",
    "        point_clouds.append(pcd)\n",
    "\n",
    "    return point_clouds\n",
    "\n",
    "\n",
    "def merge_point_clouds(point_clouds):\n",
    "    \"\"\"\n",
    "    Merges multiple Open3D PointCloud objects into a single PointCloud object.\n",
    "\n",
    "    Parameters:\n",
    "        point_clouds (list of o3d.geometry.PointCloud): A list of Open3D PointCloud objects.\n",
    "\n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: A single Open3D PointCloud object containing the merged 3D coordinates of all point clouds.\n",
    "    \"\"\"\n",
    "    # Create an empty Open3D PointCloud object to store the merged point cloud\n",
    "    merged_point_cloud = o3d.geometry.PointCloud()\n",
    "    \n",
    "    # Concatenate all the individual point clouds into a single point cloud\n",
    "    for pcd in point_clouds:\n",
    "        merged_point_cloud += pcd\n",
    "    \n",
    "    return merged_point_cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apply_tonemap # TODO TOSET uncomment if you need to get the hdf5 files with tonemap\n",
    "\n",
    "path_metadata_camera_parameters = '/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds_Hypersim/withDepths/metadata_camera_parameters.csv' # TODO TOSET: change with what you need\n",
    "base_path = '/local/home/gmarsich/data2TB/Hypersim/evermotion_dataset/scenes' # TODO TOSET: change with what you need\n",
    "scene = 'ai_007_008'  # name of the scene, with format ai_VVV_NNN # TODO TOSET: change with what you need\n",
    "cam_xx = 'cam_00' # TODO TOSET: change with what you need\n",
    "\n",
    "# Get the tonemapped images\n",
    "# TODO TOSET uncomment the following if need to get the hdf5 files with tonemap\n",
    "in_dir = os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5')\n",
    "out_dir = os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', 'scene_' + cam_xx + '_final_hdf5_TONEMAP')\n",
    "apply_tonemap.apply_tonemapping_to_directory(in_dir, out_dir)\n",
    "\n",
    "# Get list of image and depth HDF5 files\n",
    "paths_images = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_final_hdf5', 'scene_' + cam_xx + '_final_hdf5_TONEMAP', '*.color.hdf5')))\n",
    "paths_depthEuclidean = sorted(glob.glob(os.path.join(base_path, scene, 'images', 'scene_' + cam_xx + '_geometry_hdf5', '*.depth_meters.hdf5')))\n",
    "\n",
    "# Ensure the number of image and depth files match\n",
    "if len(paths_images) != len(paths_depthEuclidean):\n",
    "    raise ValueError(\"The number of image files and depth files do not match.\")\n",
    "\n",
    "# Get orientations and positions\n",
    "paths_orientations = os.path.join(base_path, scene, '_detail', cam_xx, 'camera_keyframe_orientations.hdf5')\n",
    "paths_positions = os.path.join(base_path, scene, '_detail', cam_xx, 'camera_keyframe_positions.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_files = get_depths(paths_depthEuclidean, path_metadata_camera_parameters, scene)\n",
    "\n",
    "frames_ids = extract_frames_ids(paths_depthEuclidean)\n",
    "extrinsics_matrices = get_extrinsics(paths_positions, paths_orientations, frames_ids)\n",
    "print(extrinsics_matrices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_clouds = generate_point_cloud(paths_images, depth_files, extrinsics_matrices, path_metadata_camera_parameters, scene)\n",
    "merged_point_clouds = merge_point_clouds(point_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([merged_point_clouds]) # to visualise the point cloud\n",
    "# o3d.io.write_point_cloud(\"point_cloud_DEPTHS_ai_007_008_cam_00.ply\", merged_point_clouds) # to save the point cloud as .ply file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to open a point cloud\n",
    "# pcd = o3d.io.read_point_cloud(\"/local/home/gmarsich/Desktop/Thesis/0Code_playground/pointClouds_Hypersim/withDepths/point_cloud_DEPTHS.ply\")\n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisPlayground_pointClouds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
